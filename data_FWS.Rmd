---
title: "ACCS-UAA Water Temp Data Import"
output:
  html_document: 
    df_print: paged
    fig_width: 10
    fig_height: 6
    fig_caption: yes
    code_folding: hide
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: false
      smooth_scroll: false
editor_options: 
  chunk_output_type: inline
---

Document last updated `r Sys.time()` by Benjamin Meyer (benjamin.meyer.ak@gmail.com)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# clear environment
rm(list=ls())

# load packages
library(tidyverse)
library(lubridate)
library(readr)
library(readxl)
library(hms)
library(plotly)
```


<br>

### Data Import

Read in Excel files, one at a time.  Note: data is structured such that individual sites are separated by tabs, with one tab for metadata.

Read in "Togiak_Oct2020_Part1.xlsx"
```{r}
#becky's togiak 1 dataset
#togiak1 <- "S:/Stream Temperature Data/USFWS Perdue - complete 2020/Togiak_Oct2020_Part1.xlsx"

# ben's togiak1 dataset path
togiak1 <- "data/FWS/Togiak_Oct2020_Part1.xlsx"

sheets <- excel_sheets(togiak1)
sheets <- sheets[!grepl("metadata", sheets)] # filtering to remove the metadata sheet
tog1_dat <- tibble()
for(i in sheets){
  dat <- read_excel(togiak1, sheet = i, skip = 1, col_types = c("date", "date", "text"), 
                    col_names = c("date", "time", "temp")) %>%
    mutate(SiteID = i)
  tog1_dat <- bind_rows(tog1_dat, dat)
}

```

<br>

Read in "Togiak_Oct2020_Part2.xlsx"
```{r}
# ben's togiak2 dataset path
togiak2 <- "data/FWS/Togiak_Oct2020_Part2.xlsx"

sheets <- excel_sheets(togiak2)
sheets <- sheets[!grepl("metadata", sheets)] # filtering to remove the metadata sheet
tog2_dat <- tibble()
for(i in sheets){
  dat <- read_excel(togiak2, 
                    sheet = i, 
                    skip = 1, 
                    col_types = c("date", "date", "text"), 
                    col_names = c("date", "time", "temp")) %>%
    mutate(SiteID = i)
  tog2_dat <- bind_rows(tog2_dat, dat)
}

```

<br>

Read in Egegik data, "WRB_Oct2020.xlsx"
```{r}
# ben's egegik dataset path
egegik <- "data/FWS/WRB_Oct2020.xlsx"

sheets <- excel_sheets(egegik)
sheets <- sheets[!grepl("metadata", sheets)] # filtering to remove the metadata sheet
egegik_dat <- tibble()
for(i in sheets){
  dat <- read_excel(egegik, 
                    sheet = i, 
                    skip = 1, 
                    col_types = c("date", "date", "text"), 
                    col_names = c("date", "time", "temp")) %>%
    mutate(SiteID = i)
  egegik_dat <- bind_rows(egegik_dat, dat)
}

```

<br>

Combine the three data sources and format as specified in Project_notes.Rmd
```{r}
fws.data <- bind_rows(tog1_dat,tog2_dat,egegik_dat) %>%
  rename(Temperature = temp,
         sampleTime = time,
         sampleDate = date) %>%
  transform(Temperature = as.numeric(Temperature),
            sampleDate = as.Date(sampleDate),
            sampleTime = hms::as.hms(sampleTime)) %>%
  filter(!is.na(Temperature))

```

<br>

Read in metadata and use to assign AKOATS_IDs
```{r}
# togiak1
togiak1_metadata <- read_excel("data/FWS/Togiak_Oct2020_Part1.xlsx", sheet = "AKOATS_metadata")

#togiak2
togiak2_metadata <- read_excel("data/FWS/Togiak_Oct2020_Part2.xlsx", sheet = "AKOATS_metadata")

#egegik
egegik_metadata <- read_excel("data/FWS/WRB_Oct2020.xlsx", sheet = "AKOATS_metadata")

# combine metadata sheets
fws.metadata <- bind_rows(togiak1_metadata,togiak2_metadata,egegik_metadata) %>%
  select(AKOATS_ID,SiteID,Waterbody_name)

# join metadata to data
fws.data <- left_join(fws.data,fws.metadata,by = "SiteID") %>%
  distinct()

# remove extraneous objects
rm(togiak1_metadata,togiak2_metadata,egegik_metadata,egegik_dat,tog1_dat,tog2_dat,dat)

```

<br>

Perform a quick visualization and summary table to see extent and form of original data.

* Summary table

```{r}
# create data summary table
fws.data.summary <- fws.data %>%
  mutate(year = year(sampleDate)) %>%
  group_by(SiteID,year) %>%
  summarize(meanTemp = mean(Temperature, na.rm = T),
            maxTemp = max(Temperature, na.rm = T),
            minTemp = min(Temperature, na.rm = T),
            sdTemp = sd(Temperature, na.rm = T),
            n_obs = n())

fws.data.summary %>%
  datatable() %>%
  formatRound(columns=c("meanTemp","maxTemp","minTemp","sdTemp"), digits=2)
    
```
<br>

* Visualization

```{r}
fws.data %>%
  select(-sampleTime) %>%
  mutate(year = as.factor(year(sampleDate)),
         day = yday(sampleDate)) %>%
  group_by(day,SiteID,Waterbody_name,year) %>%
  summarise(daily_mean_Temperature = mean(Temperature)) %>%
  ggplot(aes(day,daily_mean_Temperature, color = year)) +
  geom_point() +
  facet_wrap(. ~ Waterbody_name) +
  ggtitle("Original Logger Data by Site and Year - Daily Mean")

```

<br>

A quick visualization does not reveal many dramatically obvious signs of logger malfunction.  Export for now, will more carefully re-examine later.


Assign useData column
```{r}
fws.data <- fws.data %>%
  mutate(useData = 1)
```

<br>

To do: Flag erroneous data, and assign "useData = 0" to erroneous/flagged data.

<br>


Export csv of combined datasets, with newly identified "do not use data" signified with a "0" in the useData column, to data folder associated with this .Rproj
```{r}
# reorder columns
x <- fws.data %>% select(AKOATS_ID,SiteID,sampleDate,sampleTime,Temperature,useData)

# export csv
write.csv(x,"output/FWS.csv", row.names = F)

```

