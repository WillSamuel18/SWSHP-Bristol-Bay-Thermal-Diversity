---
title: "ACCS-UAA Water Temp Data Import"
output:
  html_document: 
    df_print: paged
    fig_width: 10
    fig_height: 6
    fig_caption: yes
    code_folding: hide
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: false
      smooth_scroll: false
editor_options: 
  chunk_output_type: inline
---

Document last updated `r Sys.time()` by Benjamin Meyer (benjamin.meyer.ak@gmail.com)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = normalizePath(".."))

# clear environment
rm(list=ls())

# load packages
library(tidyverse)
library(lubridate)
library(readr)
library(readxl)
library(hms)
library(plotly)
```

Note that we need to get the knb download for Meg's data. 


### Data Import

Read in Excel files, one at a time.  Note: data is structured such that individual sites are separated by tabs, with one tab for metadata.

Read in "Togiak_Oct2020_Part1.xlsx"
```{r}

togiak1 <- "data/FWS/Togiak_Oct2020_Part1.xlsx"

sheets <- excel_sheets(togiak1)
sheets <- sheets[!grepl("metadata", sheets)] # filtering to remove the metadata sheet
tog1_dat <- tibble()
for(i in sheets){
  dat <- read_excel(togiak1, sheet = i, skip = 1, col_types = c("date", "date", "text"), 
                    col_names = c("sampleDate", "sampleTime", "Temperature")) %>%
    mutate(SiteID = i)
  tog1_dat <- bind_rows(tog1_dat, dat)
}

tog1_dat
```



Read in "Togiak_Oct2020_Part2.xlsx"
```{r}
togiak2 <- "data/FWS/Togiak_Oct2020_Part2.xlsx"

sheets <- excel_sheets(togiak2)
sheets <- sheets[!grepl("metadata", sheets)] # filtering to remove the metadata sheet
tog2_dat <- tibble()
for(i in sheets){
  dat <- read_excel(togiak2, 
                    sheet = i, 
                    skip = 1, 
                    col_types = c("date", "date", "text"), 
                    col_names = c("sampleDate", "sampleTime", "Temperature")) %>%
    mutate(SiteID = i)
  tog2_dat <- bind_rows(tog2_dat, dat)
}

tog2_dat
```

<br>

Read in Egegik data, "WRB_Oct2020.xlsx"
```{r}
egegik <- read_excel("data/FWS/WRB_Oct2020.xlsx", sheet = "580223156504200", skip = 1, 
                    col_types = c("date", "date", "text"), col_names = c("sampleDate", "sampleTime", "Temperature")) %>% 
  mutate(SiteID = "580223156504200")

egegik
```

<br>

Combine the three data sources and format as specified in Project_notes.Rmd
```{r}
fws.data <- bind_rows(tog1_dat,tog2_dat,egegik) %>%
  mutate(Temperature = as.numeric(Temperature),
         sampleTime = hms::as_hms(sampleTime),
         sampleDate = as.Date(sampleDate)) %>%
  filter(!is.na(Temperature))

fws.data %>% 
  distinct(SiteID)

```


<br>

Read in metadata and use to assign AKOATS_IDs. Note same metadata in both workbooks, only need one.


```{r}
togiak1_metadata <- read_excel("data/FWS/Togiak_Oct2020_Part1.xlsx", sheet = "AKOATS_metadata") %>% 
  filter(!is.na(SourceName))

# togiak2_metadata <- read_excel("data/FWS/Togiak_Oct2020_Part2.xlsx", sheet = "AKOATS_metadata") %>% 
#   filter(!is.na(SourceName))

wrb_metadata <- read_excel("data/FWS/WRB_Oct2020.xlsx", sheet = "AKOATS_metadata", n_max = 15) %>% 
  mutate(SiteID = as.character(SiteID)) %>% 
  filter(Waterbody_name %in% c("Egegik River"))

# combine metadata sheets
fws.metadata <- bind_rows(togiak1_metadata, wrb_metadata) %>%
  select(SourceName, AKOATS_ID, SiteID, Waterbody_name, Latitude, Longitude)

saveRDS(fws.metadata, "output/fws_metadata.rds")

# join metadata to data
fws.data <- left_join(fws.data, fws.metadata %>% select(SiteID, Waterbody_name), by = "SiteID") 

# remove extraneous objects
rm(togiak1_metadata,togiak2_metadata,tog1_dat,tog2_dat,dat)

```


Summary csv to add as attributes to leaflet map.

```{r}
fws.data %>% 
  group_by(SiteID, Waterbody_name) %>% 
  summarize(startYear = min(year(sampleDate)),
            endYear = max(year(sampleDate)),
            totYears = length(unique(year(sampleDate)))) %>% 
  saveRDS("output/fws_data_summ.rds")

```

Save data for summary table and figure.

```{r}
saveRDS(fws.data, "output/fws_data.rds")
```


<br>

Perform a quick visualization and summary table to see extent and form of original data.

* Summary table

```{r}
# create data summary table
fws.data.summary <- fws.data %>%
  mutate(year = year(sampleDate)) %>%
  group_by(SiteID,year) %>%
  summarize(meanTemp = mean(Temperature, na.rm = T),
            maxTemp = max(Temperature, na.rm = T),
            minTemp = min(Temperature, na.rm = T),
            sdTemp = sd(Temperature, na.rm = T),
            n_obs = n())

fws.data.summary %>%
  datatable() %>%
  formatRound(columns=c("meanTemp","maxTemp","minTemp","sdTemp"), digits=2)
    
```
<br>

* Visualization

```{r}
fws.data %>%
  select(-sampleTime) %>%
  mutate(year = as.factor(year(sampleDate)),
         day = yday(sampleDate)) %>%
  group_by(day,SiteID,Waterbody_name,year) %>%
  summarise(daily_mean_Temperature = mean(Temperature)) %>%
  ggplot(aes(day,daily_mean_Temperature, color = year)) +
  geom_point() +
  facet_wrap(. ~ Waterbody_name) +
  ggtitle("Original Logger Data by Site and Year - Daily Mean")

```

<br>

A quick visualization does not reveal many dramatically obvious signs of logger malfunction.  Export for now, will more carefully re-examine later.


Assign useData column
```{r}
fws.data <- fws.data %>%
  mutate(useData = 1)
```

<br>

To do: Flag erroneous data, and assign "useData = 0" to erroneous/flagged data.

<br>


Export csv of combined datasets, with newly identified "do not use data" signified with a "0" in the useData column, to data folder associated with this .Rproj
```{r}
# reorder columns
x <- fws.data %>% select(AKOATS_ID,SiteID,sampleDate,sampleTime,Temperature,useData)

# export csv
write.csv(x,"output/FWS.csv", row.names = F)

```

