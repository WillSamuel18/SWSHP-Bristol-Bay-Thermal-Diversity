---
title: "All Sites Metadata"
output:
  html_document: 
    df_print: paged
    fig_width: 10
    fig_height: 6
    fig_caption: yes
    code_folding: hide
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: false
      smooth_scroll: false
editor_options: 
  chunk_output_type: inline
---

Document last updated `r Sys.time()` by Benjamin Meyer (benjamin.meyer.ak@gmail.com)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# clear environment
rm(list=ls())

# load packages
library(tidyverse)
library(lubridate)
library(readr)
library(readxl)
library(hms)
library(plotly)
library(DT)
library(dataRetrieval)

# define function to exclude multiple strings in a column
'%ni%' <- Negate('%in%')
```

<br>

Summarize extent and metadata of all successfully read-in data so date

Create list of unique data sets by site and year from read-in folder (`\data`)
```{r warning=FALSE}

# read in streams & beaches
dat <-list.files(path = paste0("output"),
               pattern = "*.csv", 
               full.names = T) %>%
     map_df(function(x) read_csv(x,skip = 1,col_types = cols(.default = "c"),col_names = F) %>% 
            mutate(filename = gsub(".csv","",basename(x))))
# rename columns
colnames(dat) <- c("AKOATS_ID","SiteID","Date","Time","Temperature","useData","filename")

# how many streams & beaches observations? (7,429,464)
n_obs_sb <- nrow(dat)

# read in lakes
dat.lakes <-list.files(path = paste0("output/Lakes"),
               pattern = "*.csv", 
               full.names = T) %>%
     map_df(function(x) read_csv(x,skip = 1,col_names = F) %>% 
            mutate(filename = gsub(".csv","",basename(x))))
# rename columns
colnames(dat.lakes) <- c("AKOATS_ID","SiteID","Depth","Date","Time","Temperature","useData","filename")

# how many lakes observations? (5,467,621)
n_obs_lakes <- nrow(dat.lakes)

```

<br>

Visualization exercise: if each water temperature observation in our enormous data set were an average sized sockeye, what distance would it stretch end to end?
```{r Analogy}

# average sockeye FL = 2 ft = 609.6 mm
# earth circumference = 40,007.863 km
# distance from Seattle to Tokyo = 7,712 km

sockeye.length.km <- 609.6 / 1000000 # length of one sockeye in km
total_obs <- n_obs_sb + n_obs_lakes
dist <- total_obs * sockeye.length.km # = 8100 km

```

If each of the observations in our data set were an average sized sockeye salmon (~2 ft), they would stretch `r dist` km end to end, that's 300 km more than the distance from Seattle to Tokyo!

We have a total of `r n_obs_sb` individual streams & beaches temperature observations!  And, we have a total of `r n_obs_lakes` observations from multi-level buoy lake sites!  


<br>

Associate metadata with all temp data sets.  Proceed one agency at a time, as it is not all in a consistent format.

Note: original approach involved collating all metadata to a single table, then using left_join to assign to overall data frame either by AKOATS_ID or SiteID.  However computer processing power was insufficient to handle this task.  Thus metadata is joined one-at-a-time by agency.

* AKOATS metadata

```{r}
akoats.meta <- read_excel("data/AKOATS_DATA_2020_Working.xlsx", sheet = "AKOATS_COMPLETE", col_types = "text") %>%
  select(seq_id,Agency_ID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) %>%
  rename(AKOATS_ID = seq_id,
         SiteID = Agency_ID)
```

<br>

* UW metadata

```{r}
# UW metadata
# read in UW metadata resolutions emailed from R Shaftel on 11/13/20
uw.meta <- read_excel("data/Jackie Carter UW/uw_metadata_thru_2017.xlsx", sheet = "Sheet1") %>%
  # still waiting on Lynx Creek SiteID reslutions, so exclude for now
  # filter(data_SiteID != "UW-FRI_LynxCreekALL_Temps") %>%
  # use only one AKOATS_ID for sites with multiple entries
  separate(AKOATS_ID, sep = " and", into = "AKOATS_ID") %>%
  separate(AKOATS_ID, sep = " or", into = "AKOATS_ID") %>%
  select(-rss_notes, -`jc_notes Nov13`, -BM_notes,-fileName) %>%
  # remove degree symbols
  mutate(Latitude = as.double(gsub("°","",Latitude)),
         Longitude = as.double(gsub("°","",Longitude))) %>%
  # create other metadata as possible as known
  mutate(Contact_person = "Jackie Carter",
         Contact_email = "jlcarter@uw.edu",
         SourceName = "uwASP",
         Contact_telephone = "206-543-7563",
         Sensor_accuracy = "",
         Waterbody_name = "")  %>%
  # retain only sites missing an AKOATS_ID and instead have coords provided by UW
  filter(AKOATS_ID == "NA") %>%
  rename(SiteID = StationName) %>%
  mutate_all(as.character)

# join with AKOATS-provided metadata where possible, and use UW provided metadata where not

# all uw metadata w/ AKOATS IDs
uw.meta.1 <- bind_rows(akoats.meta,uw.meta) %>%
  filter(SourceName == "uwASP",
         !is.na(AKOATS_ID))

# join uw.meta.1 metadata to overall dataframe (join by AKOATS_ID)
dat.uw.1 <- dat %>%
  filter(filename == "UW",
         !is.na(filename)) %>%
  select(-SiteID) %>%
  inner_join(uw.meta.1, by = "AKOATS_ID")


# all uw metadata WITHOUT AKOATS IDs
uw.meta.2 <- bind_rows(akoats.meta,uw.meta) %>%
  filter(SourceName == "uwASP",
         is.na(AKOATS_ID)) %>%
  select(-AKOATS_ID)

# join uw.meta.2 metadata to overall dataframe (join by SiteID)
dat.uw.2 <- dat %>%
  filter(filename == "UW",
         is.na(AKOATS_ID)) %>%
  inner_join(uw.meta.2, by = "SiteID")

uw.dat <- bind_rows(dat.uw.1,dat.uw.2) %>%
  mutate_all(as.character)

rm(uw.meta,uw.meta.1,uw.meta.2,dat.uw.1,dat.uw.2)

```

<br>

* CIK metadata

```{r}

# CIK metadata from AKOATS database
cik.meta.1 <- akoats.meta %>%
  filter(SourceName == "CIK") %>%
  mutate_all(as.character)

# CIK metadata from provided excel file
cik.meta.2 <- read_excel("data/CIK Bristol Bay village and lodge sites/cik_metadata/CIK Bristol Bay village and lodge sites.xlsx") %>%
  separate(`KNB ID`, sep = "_",into = c("a","AKOATS_ID")) %>%
  select(SiteID,AKOATS_ID,Waterbody_name) %>%
  filter(!is.na(AKOATS_ID)) %>%
  distinct() %>%
  mutate_all(as.character)

# "Ben Courtney Creek" location missing.  Coordinates provided via email from Sue Mauger on 11/16/20 @ 59.272417; -156.357567

# create ben courtney creek metadata
cik.meta.bc <- data.frame("Ben Courtney Creek") %>%
  mutate(AKOATS_ID = as.character(""),
         SiteID = "Ben Courtney Creek",
         Contact_person = "Sue Mauger",
         SourceName = "CIK",
         Contact_email = "sue@inletkeeper.org",
         Contact_telephone = "907-235-4068",
         Latitude = 59.272417,
         Longitude = -156.357567,
         Sensor_accuracy = "") %>%
  select(-X.Ben.Courtney.Creek.) %>%
  mutate_all(as.character)

# also missing Roadhouse Creek info!

# join ben courtney creek metadata to other CIK metadata
cik.meta <- bind_rows(cik.meta.1,cik.meta.2,cik.meta.bc) %>%
  filter(!is.na(SourceName))

# join with AKOATS-provided metadata where possible, and use CIK provided metadata where not
dat.cik <- dat %>%
  filter(filename == "CIK") %>%
  select(-AKOATS_ID) %>%
  left_join(cik.meta, by = "SiteID") %>%
  distinct() %>%
  mutate_all(as.character)

rm(cik.meta,cik.meta.1,cik.meta.2,cik.meta.bc)
```

<br>

* FWS metadata

```{r}
# FWS metadata
togiak1.meta <- read_excel("data/FWS/Togiak_Oct2020_Part1.xlsx", sheet = "AKOATS_metadata")
togiak2.meta <- read_excel("data/FWS/Togiak_Oct2020_Part2.xlsx", sheet = "AKOATS_metadata")
egegik.meta <- read_excel("data/FWS/WRB_Oct2020.xlsx", sheet = "AKOATS_metadata")
fws.meta <- bind_rows(togiak1.meta,togiak2.meta,egegik.meta)

# specify strings to remove
strings <- c("I have no data for Togiak Lake",
             "I have no data for Togiak lake",
             "New Sites:",
             "was wrongly named as 571001154134300",
             "was wrongly named as 571359154244300",
             "was wrongly named as 580223156504200")

# format fws metadata
fws.meta <- fws.meta %>% 
  # choose columns to retain
  select(AKOATS_ID,SiteID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) %>%
  filter(SiteID %ni% strings,
         !is.na(SiteID)) %>%
  distinct() 

# join fws data to metadata
fws.dat <- dat %>%
  filter(filename == "FWS") %>%
  select(-AKOATS_ID) %>%
  left_join(fws.meta,by = "SiteID") %>%
  mutate_all(as.character)

# note: in the metadata tab in "WRB_Oct2020.xlsx", there are three rows describing previous "wrongly named" sites, their associated AKOATS_ID, and the correct names.  Changes made are highlighted by row in yellow in "data/AKOATS_DATA_2020_working.xlsx"

rm(togiak1.meta,togiak2.meta,egegik.meta,fws.meta)
```

<br>

* UAA-ACCS metadata

```{r}
# UAA-ACCS metadata
accs.meta <- read_csv("data/ACCS-UAA/metadata/SiteLevelMetadata_Bogan.csv", col_types = cols(.default = "c")) %>%
  select(AKOATS_ID,SiteID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) 


# join uaa-accs data to metadata
accs.dat <- dat %>%
  filter(filename == "UAA-ACCS") %>%
  select(-SiteID) %>%
  left_join(accs.meta,by = "AKOATS_ID") %>%
  mutate_all(as.character)

rm(accs.meta)

```

<br>

* NPS metadata

```{r}
# We will use AKOATS provided metadata where available.  However a number of NPS sites do not have AKOATs_ID values,  so use NPS-provided metadata in these cases.

# AKOATS-provided metadata - streams & beaches
nps.names.sb <- dat %>%
  filter(filename == "NPS_streams_beaches") %>%
  select(SiteID) %>%
  distinct() %>%
  inner_join(akoats.meta) %>%
  select(AKOATS_ID,SiteID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) 

# AKOATS-provided metadata - lakes
nps.names.lakes <- dat.lakes %>%
  filter(filename == "NPS_lakes") %>%
  select(SiteID) %>%
  distinct() %>%
  inner_join(akoats.meta) %>%
  select(AKOATS_ID,SiteID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) 

# combine
nps.meta.1 <- bind_rows(nps.names.sb,nps.names.lakes) %>%
  mutate_all(as.character)

# which NPS sites are missing from AKOATS-provided metadata?

## list of all NPS site names
## streams & beaches
nps.names.sb <- dat %>%
  filter(filename == "NPS_streams_beaches") %>%
  select(SiteID) %>%
  distinct() %>%
  data.frame()

## lakes
nps.names.lakes <- dat.lakes %>%
  filter(filename == "NPS_lakes") %>%
  select(SiteID) %>%
  distinct() %>%
  data.frame()

## get metadata for these sites from NPS-provided sheet
nps.names.missing <- bind_rows(nps.names.sb,nps.names.lakes) %>%
  anti_join(akoats.meta)

# read in NPS-provided
nps.meta.2 <- read_excel("data/NPS Bartz/Site_Info.xlsx", skip = 4) %>%
  rename(SiteID = Agency_ID,
         Latitude = Lat,
         Longitude = Long,
         Waterbody_name = Waterbody_Name) %>%
  inner_join(nps.names.missing) %>%
  mutate(AKOATS_ID = as.double(""),
         Contact_person = "Krista Bartz",
         Contact_email = "krista_bartz@nps.gov",
         Contact_telephone = "(907) 644-3685",
         SourceName = "npsSWAN",
         Sensor_accuracy = "") %>%
  select(AKOATS_ID,SiteID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) %>%
  mutate_all(as.character)

# join all available NPS metadata
nps.meta <- bind_rows(nps.meta.1,nps.meta.2)

# join NPS streams & beaches data to metadata
nps.dat.sb <- dat %>%
  filter(filename == "NPS_streams_beaches") %>%
  select(-AKOATS_ID) %>%
  left_join(nps.meta,by = "SiteID") %>%
  mutate_all(as.character)

# join NPS lakes data to metadata
nps.dat.lakes <- dat.lakes %>%
  select(-AKOATS_ID) %>%
  left_join(nps.meta,by = "SiteID") %>%
  mutate_all(as.character)

rm(nps.meta,nps.meta.1,nps.meta.2,nps.names.sb,nps.names.missing,nps.names.lakes)
```

<br>

* USGS metadata

```{r}
# USGS metadata
## read in directly from online w/ readNWIS pkg fxn
usgs.sites <- c("15302000","15300300","15302250","15302812")
usgs.meta <- readNWISsite(usgs.sites)

# examine akoats meta data for usgs sites
usgs.meta.akoats <- akoats.meta %>% filter(SiteID %in% usgs.sites)

# note: there is no AKOATS_ID yet for USGS site 15302812 ("KOKWOK R 22 MI AB NUSHAGAK R NR EKWOK AK)

# create metadata for site missing from akoats
usgs.meta.1 <- usgs.meta %>%
  filter(site_no == "15302812") %>%
  select(site_no,station_nm,dec_lat_va,dec_long_va) %>%
  mutate(AKOATS_ID = "",
         Contact_person = "",
         SourceName = "USGS",
         Contact_email = "",
         Contact_telephone ="",
         Sensor_accuracy = "",
         Waterbody_name = "Ekwok River") %>%
  rename(SiteID = site_no,
         Latitude = dec_lat_va,
         Longitude = dec_long_va) %>%
  select(AKOATS_ID,SiteID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) %>%
  mutate_all(as.character)

# format usgs-provided metadata to match other metadata
usgs.meta.2 <- usgs.meta %>%
  filter(site_no != "15302812") %>%
  rename(SiteID = site_no) %>%
  left_join(usgs.meta.akoats,by = "SiteID") %>%
  select(AKOATS_ID,SiteID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) %>%
  mutate_all(as.character)

# join usgs metadata to single table
usgs.meta <- bind_rows(usgs.meta.1,usgs.meta.2) 

# join usgs data to metadata
usgs.dat <- dat %>%
  filter(filename == "USGS") %>%
  select(-AKOATS_ID) %>%
  left_join(usgs.meta,by = "SiteID") %>%
  mutate_all(as.character)

rm(usgs.meta,usgs.meta.1,usgs.meta.2,usgs.meta.akoats)

```

<br>


Join all data in to one table (takes a few minutes...)
```{r}
# combine
dat <- bind_rows(uw.dat,dat.cik,fws.dat,accs.dat,nps.dat.sb,usgs.dat) 
rm(uw.dat,dat.cik,fws.dat,accs.dat,nps.dat.sb,usgs.dat)

# prep for summary table
## streams & beaches
dat <- dat %>%
  filter(useData == 1,
         !is.na(Temperature),
         !is.na(Time)) %>%
  rename(sampleTime = Time,
         sampleDate = Date) %>%
  transform(sampleTime = hms::as_hms(sampleTime),
            sampleDate = as.Date(sampleDate),
            Temperature = as.numeric(Temperature)) %>%
  mutate(year = year(sampleDate)) 

## lakes
dat.lakes <- nps.dat.lakes %>%
  filter(useData == 1,
         !is.na(Temperature)) %>%
  rename(sampleTime = Time,
         sampleDate = Date) %>%
  transform(sampleTime = hms::as_hms(sampleTime),
            sampleDate = as.Date(sampleDate),
            Tempreature = as.numeric(Temperature)) %>%
  mutate(year = year(sampleDate)) 

```

<br>

Create summary metadata table
```{r}
z <- dat %>%
  
  group_by(AKOATS_ID,SiteID,Contact_person,SourceName,Latitude,Longitude,Sensor_accuracy,Waterbody_name) %>%
  summarise(start_year = min(year),
            end_year = max(year),
            max_temp = max(Temperature),
            min_temp = min(Temperature),
            mean_temp = mean(Temperature)
            )

# Panaraquk Creek and Gibralter River should have coords, see CIK metadata file

```




<br>

Join all metadata to all lakes data
```{r}
z <- nps.dat.lakes %>%

```





working here 11/16/20


<br>

Join to AKOATS metadata table

Summarize by year, site, agency
- min/max/mean/sd
- n_obs
- frequency obs
- years extent

<br>

Export metadata summary table

Create leaflet map (in diff script maybe)

