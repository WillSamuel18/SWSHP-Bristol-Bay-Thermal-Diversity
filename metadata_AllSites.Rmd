---
title: "All Sites Metadata"
output:
  html_document: 
    df_print: paged
    fig_width: 10
    fig_height: 6
    fig_caption: yes
    code_folding: hide
    toc: true
    toc_depth: 4
    toc_float:
      collapsed: false
      smooth_scroll: false
editor_options: 
  chunk_output_type: inline
---

Document last updated `r Sys.time()` by Benjamin Meyer (benjamin.meyer.ak@gmail.com)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# clear environment
rm(list=ls())

# load packages
library(tidyverse)
library(lubridate)
library(readr)
library(readxl)
library(hms)
library(plotly)
library(DT)
library(dataRetrieval)

# define function to exclude multiple strings in a column
'%ni%' <- Negate('%in%')
```

<br>

Summarize extent and metadata of all successfully read-in data so date

Create list of unique data sets by site and year from read-in folder (`\data`)
```{r warning=FALSE}

# read in streams & beaches
dat <-list.files(path = paste0("output"),
               pattern = "*.csv", 
               full.names = T) %>%
     map_df(function(x) read_csv(x,skip = 1,col_names = F) %>% 
            mutate(filename = gsub(".csv","",basename(x))))

colnames(dat) <- c("AKOATS_ID","SiteID","Date","Time","Temperature","useData","filename")

# how many streams & beaches observations? (7,429,464)
n_obs_sb <- nrow(dat)

# read in lakes
dat.lakes <-list.files(path = paste0("output/Lakes"),
               pattern = "*.csv", 
               full.names = T) %>%
     map_df(function(x) read_csv(x,skip = 1,col_names = F) %>% 
            mutate(filename = gsub(".csv","",basename(x))))

# how many lakes observations? (5,467,621)
n_obs_lakes <- nrow(dat.lakes)

```


We have a total of `r n_obs_sb` individual streams & beaches temperature observations!  And, we have a total of `r n_obs_lakes` observations from multi-level buoy sites!

<br>

Associate metadata with all temp data sets.  Proceed one agency at a time, as it is not all in a consistent format.

AKOATS metadata
```{r}
akoats.meta <- read_excel("data/AKOATS_DATA_2020_Working.xlsx", sheet = "AKOATS_COMPLETE") %>%
  select(seq_id,Agency_ID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) %>%
  rename(AKOATS_ID = seq_id,
         SiteID = Agency_ID)
```

<br>

UW metadata
```{r}
# UW metadata
# read in UW metadata resolutions emailed from R Shaftel on 11/13/20
uw.meta <- read_excel("data/Jackie Carter UW/uw sites_JC_rss.xlsx", sheet = "Sheet1") %>%
  # still waiting on Lynx Creek SiteID reslutions, so exclude for now
  filter(data_SiteID != "UW-FRI_LynxCreekALL_Temps") %>%
  # use only one AKOATS_ID for sites with multiple entries
  separate(AKOATS_ID, sep = " and", into = "AKOATS_ID") %>%
  select(-Notes) %>%
  # remove degree symbols
  mutate(Latitude = as.double(gsub("°","",Latitude)),
         Longitude = as.double(gsub("°","",Longitude))) %>%
  # create other metadata as possible as known
  mutate(Contact_person = "Jackie Carter",
         Contact_email = "jlcarter@uw.edu",
         SourceName = "uwASP",
         Contact_telephone = "206-543-7563") %>%
  rename(SiteID = data_SiteID)

# join with AKOATS-provided metadata where possible, and use UW provided metadata where not
## uw sites WITHOUT AKOATS_ID values
uw.meta <- uw.meta %>%
  filter(AKOATS_ID == "NA") %>%
  transform(AKOATS_ID = as.double(AKOATS_ID))

# all uw metadata
uw.meta <- bind_rows(akoats.meta,uw.meta) %>%
  filter(SourceName == "uwASP")

```

<br>

CIK metadata
```{r}

# CIK metadata
cik.meta <- akoats.meta %>%
  filter(SourceName == "CIK") 

# "Ben Courtney Creek" location missing.  Coordinates provided via email from Sue Mauger on 11/16/20 @ 59.272417; -156.357567

# create ben courtney creek metadata
cik.meta.bc <- data.frame("Ben Courtney Creek") %>%
  mutate(AKOATS_ID = as.double("NA"),
         SiteID = "Ben Courtney Creek",
         Contact_person = "Sue Mauger",
         SourceName = "CIK",
         Contact_email = "sue@inletkeeper.org",
         Contact_telephone = "907-235-4068",
         Latitude = 59.272417,
         Longitude = -156.357567,
         Sensor_accuracy = "") %>%
  select(-X.Ben.Courtney.Creek.)

# join ben courtney creek metadata to other CIK metadata
cik.meta <- bind_rows(cik.meta,cik.meta.bc)

rm(cik.meta.bc)
```

<br>

FWS metadata
```{r}
# FWS metadata
togiak1.meta <- read_excel("data/FWS/Togiak_Oct2020_Part1.xlsx", sheet = "AKOATS_metadata")
togiak2.meta <- read_excel("data/FWS/Togiak_Oct2020_Part2.xlsx", sheet = "AKOATS_metadata")
egegik.meta <- read_excel("data/FWS/WRB_Oct2020.xlsx", sheet = "AKOATS_metadata")
fws.meta <- bind_rows(togiak1.meta,togiak2.meta,egegik.meta)


# specify strings to remove
strings <- c("I have no data for Togiak Lake","I have no data for Togiak lake","New Sites:",
             "was wrongly named as 571001154134300",
             "was wrongly named as 571359154244300",
             "was wrongly named as 580223156504200")
fws.meta <- fws.meta %>% 
  # choose columns to retain
  select(AKOATS_ID,SiteID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) %>%
  filter(SiteID %ni% strings,
         !is.na(SiteID))

# note: in the metadata tab in "WRB_Oct2020.xlsx", there are three rows describing previous "wrongly named" sites, their associated AKOATS_ID, and the correct names.  Changes are highlighted by row in yellow in "data/AKOATS_DATA_2020_working.xlsx"

rm(togiak1.meta,togiak2.meta,egegik.meta)
```

<br>

UAA-ACCS metadata
```{r}
# UAA-ACCS metadata
accs.meta <- read.csv("data/ACCS-UAA/metadata/SiteLevelMetadata_Bogan.csv") %>%
  select(AKOATS_ID,SiteID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) 

# perfect!

```

<br>

NPS metadata
```{r}
# read in sheet linking site names to AKOATS_IDs

# note 11/17/20 -- currently re-working the NPS import process


```





```{r}
# NPS metadata
nps.meta <- read_excel("data/NPS Bartz/Site_Info.xlsx", skip = 4) %>%
  mutate(SiteID = paste0(Agency_ID,"_",Waterbody_Name)) %>%
  select(Lat,Long,SiteID) %>%
  rename(Latitude = Lat,
         Longitude = Long) %>%
  arrange(SiteID)

# join metadata provided by K Bartz to AKOATS_ID using table manually generated by B Meyer (too many site and waterbody name conflicts to use a purely script-based approach)
nps.meta.1 <- read_excel("data/NPS Bartz/NPS_sitename_conflicts_resolved.xlsx", sheet = "Sheet1") %>%
  select(AKOATS_ID,SiteID) %>%
  transform(AKOATS_ID = as.character(AKOATS_ID)) %>%
  arrange(SiteID)

# AKOATS_ID disappears at this step --- why?
test <- left_join(nps.meta,nps.meta.1,by = c("SiteID"))
rm(test)

# Note: we want to join nps.meta and nps.meta.1 to be able to assign an AKOATS_ID to the SiteID.  The usual command to use would be "left_join" or merge by = "SiteID."  However when I attempt this, the "AKOATS_ID" column converts to all NA.  Not able to diagnose cause or solution.

# Alternative solution: use "bind_cols" to join the two dataframe.  Make sure rows are all in exact same order beforehand.  Using "bind_cols" not normally recommended for most purposes.
nps.meta <- bind_cols(nps.meta,nps.meta.1) %>%
  select(-`SiteID...5`,-Latitude,-Longitude) %>%
  rename(SiteID = `SiteID...3`) %>%
  transform(AKOATS_ID = as.double(AKOATS_ID))

# join SiteIDs to AKOATS metadata
z <- akoats.meta %>%
  select(-SiteID) %>%
  
  full_join(nps.meta,by = "AKOATS_ID")


rm(nps.meta.1)
# Note: or NPS data, Agency_ID + Waterbody name is the unique ID.  Either of them alone do not provide a unique ID
```

<br>

USGS metadata
```{r}
# USGS metadata
## read in directly from online w/ readNWIS pkg fxn
usgs.sites <- c("15302000","15300300","15302250","15302812")
usgs.meta <- readNWISsite(usgs.sites)

# examine akoats meta data for usgs sites
usgs.meta.akoats <- akoats.meta %>%filter(SiteID %in% usgs.sites)

# note: there is no AKOATS_ID yet for USGS site 15302812 ("KOKWOK R 22 MI AB NUSHAGAK R NR EKWOK AK)

# create metadata for site missing from akoats
usgs.meta.1 <- usgs.meta %>%
  filter(site_no == "15302812") %>%
  select(site_no,station_nm,dec_lat_va,dec_long_va) %>%
  mutate(AKOATS_ID = "",
         Contact_person = "",
         SourceName = "USGS",
         Contact_email = "",
         Contact_telephone ="",
         Sensor_accuracy = "",
         Waterbody_name = "Ekwok River") %>%
  rename(SiteID = site_no,
         Latitude = dec_lat_va,
         Longitude = dec_long_va) %>%
  select(AKOATS_ID,SiteID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) 

# format usgs-provided metadata to match other metadata
usgs.meta.2 <- usgs.meta %>%
  filter(site_no != "15302812") %>%
  rename(SiteID = site_no) %>%
  left_join(usgs.meta.akoats,by = "SiteID") %>%
  transform(AKOATS_ID = as.character(AKOATS_ID)) %>%
  select(AKOATS_ID,SiteID,Contact_person,SourceName,Contact_email,Contact_telephone,Latitude,Longitude,Sensor_accuracy,Waterbody_name) 

# join usgs metadata to single table
usgs.meta <- bind_rows(usgs.meta.1,usgs.meta.2) %>%
  transform(AKOATS_ID = as.double(AKOATS_ID))

rm(usgs.meta.1,usgs.meta.2,usgs.meta.akoats)

```

<br>

Join all metadata tables to one single metadata table
```{r}
z <- bind_rows(uw.meta,cik.meta,accs.meta,fws.meta,usgs.meta)

,nps.meta)


```

<br>

Join all metadata to all streams & beaches data
```{r}

# some missing akoatsids; make manual table to join by site name where needed?
```

<br>

Join all metadata to all lakes data
```{r}

```





working here 11/16/20


<br>

Join to AKOATS metadata table

Summarize by year, site, agency
- min/max/mean/sd
- n_obs
- frequency obs
- years extent

<br>

Export metadata summary table

Create leaflet map (in diff script maybe)

