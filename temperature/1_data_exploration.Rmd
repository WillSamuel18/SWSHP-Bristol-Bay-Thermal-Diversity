---
title: "1_data_exploration"
output:
  html_document: 
    df_print: paged
    fig_width: 10
    fig_height: 10
    fig_caption: yes
    code_folding: hide
    toc: true
    number_sections: true
    toc_depth: 4
    toc_float:
      collapsed: false
      smooth_scroll: false
editor_options: 
  chunk_output_type: inline
date: "2023-01-10"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)

library(tidyverse)
library(sf)
library(lubridate)
```

# Read in data from AKSSF repo

All data were combined in the AKSSF repository. Read from that project drive and filter on data from Bristol Bay.

NOTE: Data from Zenodo are incomplete and are missing the UW data from 2017 on.

```{r zenodo data, eval = FALSE}
temp <- read_csv(file = "W:/Github/AKSSF/data_preparation/final_data/zenodo1/dailyTemps.csv")

mets <- read_csv(file = "W:/Github/AKSSF/data_preparation/final_data/zenodo1/tempMetrics.csv")

md <- read_csv(file = "W:/Github/AKSSF/data_preparation/final_data/zenodo1/tempSitesMetadata.csv")

names(md)
```

Try a different dataset that Tim used for the DFA -- all years are there!

```{r DFA input data}

temp <- read_csv("W:\\Github\\AKSSF\\data_preparation\\final_data\\summer_data_wair_dayl2022-03-17.csv")
md <- read_csv("W:\\Github\\AKSSF\\data_preparation\\final_data\\md_2022-02-08.csv")
```



```{r BB data summary}
left_join(temp, md %>% select(SiteID = Site, SourceName, Region)) %>% 
  filter(Region == "Bristol Bay", grepl("UW", SiteID)) %>% 
  distinct(SiteID, year = year(sampleDate)) %>% 
  group_by(SiteID) %>% 
  summarize(years = toString(year))

```

Summary of sites that Daniel has coho salmon size data for.

Whitefish
Yako
Bear
Silver Salmon
Fifer
Lynx (main stream and below lake trib, which are two different temperature sites).
Hidden (maybe not enough fish...)


```{r plot of ST for sites with coho data}
temp %>% 
  filter(grepl("UW", SiteID)) %>% 
  distinct(SiteID) %>% 
  filter(grepl("Lynx", SiteID))

coho_sites <- c("UW_Aleknagik Pfifer Creek", "UW_Aleknagik Silver Salmon Creek", "UW_Aleknagik Yako Creek",
                "UW_Aleknagik Big Whitefish Creek", "UW_Nerka Bear Creek", "UW_Nerka Hidden Lake Creek",
                "UW_Nerka Lynx Creek", "UW_Nerka Lynx Creek Cold Tributary", "UW_Nerka Lynx Lake Tributary",
                "UW_Aleknagik Bear Creek")

temp %>% 
  filter(SiteID %in% coho_sites) %>%
  complete(SiteID, sampleDate) %>% 
  mutate(doy = format(sampleDate, "%j"),
         year = year(sampleDate)) %>%  
  ggplot() +
  geom_line(aes(x = as.Date(doy, format = "%j"), y = meanDT, color = SiteID), size = 0.5) +
  facet_wrap(~year) +
  geom_hline(aes(yintercept = 18), color = "red") + 
  theme_bw() +
  labs(x = "", y = "Mean Daily Temperature (C)") +
  theme(legend.position = "bottom") +
  guides(color=guide_legend(nrow=5,byrow=TRUE))

ggsave("output/coho_sites_daily_temps.jpeg")
```

Map of sites for each HUC8 in Bristol Bay. (Looks like the metadata I created already has HUC8 on there.)

```{r sites by huc8}

md_sf <- st_as_sf(md, coords = c("Longitude", "Latitude"), crs = "WGS84")

# huc8 <- st_read(dsn = "S:/Leslie/GIS/NHD Harmonized/WBD_19_GDB.gdb", layer = "WBDHU8")
# # st_crs(huc8)
# huc8_wgs84 <- st_transform(huc8, crs = "WGS84")
# 
# # st_crs(md_sf) == st_crs(huc8_wgs84)
# 
# md_sf <- st_join(md_sf, huc8_wgs84)


bb_huc8_names <- md_sf %>% 
  filter(Region == "Bristol Bay") %>% 
  st_drop_geometry() %>% 
  distinct(Name) %>% pull(Name)


ggplot() +
  geom_sf(data = huc8_wgs84 %>% filter(Name %in% bb_huc8_names), aes(fill = Name)) +
  geom_sf(data = md_sf %>% filter(Region == "Bristol Bay")) +
  theme_bw() +
  labs(fill = "HUC8 Name", title = "Bristol Bay Sampling Sites")

```

Plots of daily temps by HUC8 and with 18C threshold for thermal stress to adults and juveniles.

```{r}

# pdf("output/Daily summer temperatures by HUC8.pdf")

for(i in bb_huc8_names) {
  dat <- left_join(temp, md %>% select(Site, Region, Name), by = c("SiteID" = "Site")) %>% 
    filter(Region == "Bristol Bay", Name == i) %>%
    complete(SiteID, sampleDate) %>% 
    mutate(doy = format(sampleDate, "%j"),
           year = year(sampleDate))
  p1 <- dat %>% 
    ggplot() +
    geom_line(aes(x = as.Date(doy, format = "%j"), y = meanDT, group = SiteID), color = "dark gray", size = 0.5) +
    facet_wrap(~year) +
    geom_hline(aes(yintercept = 18), color = "red") + 
    theme_bw() +
    labs(x = "", title = i)
  print(p1)  
}
# dev.off()


```

Map of thermal regime classes within Bristol Bay and by year. Note that thermal regimes are ordered from coldest to warmest 6 < 1 < 2 < 3 < 4 < 5. Class 1 has latest timing of warm temps (e.g high snow inputs), and class 6 has very low variance (e.g. groundwater inputs).

* 2012 and 2013 were high snow years, but 2013 generally had quite warm summer temperatures so it must have been a very warm summer.
* 2015 and 2016 were low snow years
* 2019 was hot

```{r map of TR classes for specific years, fig.width = 8}
# TR saved for Dean in AKSSF repo
tr_grps <- read_csv(file = "W:/Github/AKSSF/output/Thermal_regimes_May22.csv")

# left_join(temp %>% mutate(Year = year(sampleDate)), tr_grps) #%>% 

tr_sf <- left_join(md_sf, tr_grps)  

# tr_sf %>% 
#   st_drop_geometry() %>% 
#   count(Year, grp_6) %>% 
#   pivot_wider(names_from = grp_6, values_from = n, names_sort = TRUE)

ggplot() +
  geom_sf(data = huc8_wgs84 %>% filter(Name %in% bb_huc8_names)) +
  geom_sf(data = tr_sf %>% filter(Region == "Bristol Bay", Year %in% c(2012, 2013, 2015, 2016, 2019)), 
          aes(color = as.factor(grp_6))) +
  facet_wrap(~Year, ncol = 2) +
  theme_bw() +
  labs(color = "Thermal Regime", Title = "Thermal Regimes by Year Across Sites in Bristol Bay")
```

Summary of watershed attributes related to UW sites in the Wood River watershed.

```{r}
mod_dat <- readRDS("W:/Github/AKSSF/data_preparation/final_data/model_data2022-05-09.rds")

mod_dat

#note that Tim had me populate all airtemps for this data frame, can remove dates without
# meandt
bb_temp <- left_join(temp, md %>% select(Site, Region, Name), by = c("SiteID" = "Site")) %>% 
    filter(Region == "Bristol Bay", !is.na(meanDT)) 

anti_join(bb_temp %>% distinct(SiteID), mod_dat %>% distinct(Site), by = c("SiteID" = "Site"))

names(bb_temp)
names(mod_dat)
mod_dat %>% select(Site, str_ord:wtd_area_sqKM) %>% distinct()

bb_temp <- left_join(bb_temp, mod_dat %>% 
            select(Site, str_ord:wtd_area_sqKM) %>% 
            distinct(), 
          by = c("SiteID" = "Site")) 

bb_temp %>% 
  distinct(SiteID, str_ord) %>% 
  # filter(is.na(str_ord))
  count(str_ord)
```


