---
title: "2_fish_data_merge"
output: html_document
date: "2023-02-09"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(readxl)
library(lubridate)
library(hms)
library(gridExtra)
```


Site list from email from Daniel:

Whitefish
Yako
Bear
Silver Salmon
Fifer
Lynx (main stream and below lake trib, which are two different temperature sites).
Hidden (maybe not enough fish...)


```{r read in coho data}

fish <- read_excel("fish/data/WR_coho.xlsx") %>% 
  mutate(StationName = case_when(grepl("Amou", StationName) ~ "Amou Creek",
                                 TRUE ~ StationName))

summary(fish)
fish %>% arrange(desc(Length))
fish %>% distinct(Species)

fish_tally <- fish %>% 
  filter(!is.na(Length)) %>% 
  count(StationName, YearSampled, name = "Coho_count")

fish %>% 
  filter(!is.na(Length)) %>% 
  count(StationName, YearSampled) %>%
  # pivot_wider(names_from = YearSampled, values_from = n, names_sort = TRUE) %>% 
  ggplot(aes(x = YearSampled, y = n, color = StationName)) +
  geom_point()


fish %>% 
  filter(!is.na(Length), Length < 300) %>% 
  ggplot(aes(x = Length, color = StationName)) +
  geom_freqpoly()


```


```{r fish data avail barplot}

fish_tally %>% 
  filter(Coho_count > 29) %>% 
  ggplot() +
  geom_raster(aes(x = YearSampled, y = StationName, fill = log(Coho_count)))

```


Crosswalk with temperature data.

```{r merge fish counts with temp data}

uw_temp <- read_csv("W:\\Github\\AKSSF\\data_preparation\\final_data\\summer_data_wair_dayl2022-03-17.csv") %>% 
  filter(grepl("UW", SiteID), !is.na(meanDT))

uw_temp %>% ungroup() %>% distinct(SiteID) #49 sites

uw_temp %>% filter(grepl("Lynx", SiteID)) %>% distinct(SiteID)

uw_temp <- uw_temp %>% 
  mutate(StationName = case_when(grepl("Silver Salmon", SiteID) ~ "Silver Salmon Creek",
                                 grepl("Big Whitefish", SiteID) ~ "Big Whitefish Creek",
                                 grepl("Aleknagik Bear", SiteID) ~ "Bear Creek", #1:1 for Bear creek
                                 grepl("Ice", SiteID) ~ "Ice Creek",
                                 grepl("Pfifer", SiteID) ~ "Pfifer Creek",
                                 grepl("Yako", SiteID) ~ "Yako Creek",
                                 grepl("Squaw", SiteID) ~ "Amou Creek",
                                 grepl("Little Whitefish", SiteID) ~ "Little Whitefish Creek",
                                 SiteID %in% c("UW_Nerka Lynx Creek", 
                                               "UW_Nerka Lynx Lake Tributary") ~ "Lynx Creek", #2:1 sites that can be matched to Lynx fish data
                                 grepl("Hidden Lake", SiteID) ~ "Hidden Lake Creek",
                                 grepl("Teal", SiteID) ~ "Teal Creek",
                                 grepl("Fenno", SiteID) ~ "Fenno Creek",
                                 grepl("Stovall", SiteID) ~ "Stovall Creek")) %>% 
  group_by(SiteID, year) %>% 
  mutate(Temp_count = n())
```

Comparison of two lynx Creek sites indicates that Lynx Creek is not a good replacement for Lynx Creek tributary, which is much warmer. Shared plot with Erik and agreed to fill data gaps for this site and possibly others with a ST model. Removed Lynx Creek from dataset, which gets rid of duplicates for three years.

```{r lynx creek sites}

uw_temp %>% 
  filter(StationName == "Lynx Creek") %>%
  mutate(day = format(sampleDate, "%m-%d")) %>% 
  ggplot(aes(x = as.Date(day, format = "%m-%d"), y = meanDT, color = SiteID)) +
  geom_line() +
  facet_wrap(~year) +
  theme_bw() +
  theme(legend.position = "bottom", axis.title.x = element_blank())

#on average, 3C warmer in trib
uw_temp %>% 
  filter(StationName == "Lynx Creek") %>%
  select(SiteID, sampleDate, meanDT) %>% 
  pivot_wider(names_from = SiteID, values_from = meanDT) %>% 
  mutate(diff = `UW_Nerka Lynx Lake Tributary` - `UW_Nerka Lynx Creek`) %>% 
  filter(!is.na(diff)) %>% 
  summarize(mean(diff), median(diff), sd(diff))

# ggsave("temperature/output/UW_fish_sites/Lynx Creek and Lake Trib Temps.jpeg")
```


```{r save ST data frame for Erik}

uw_temp <- uw_temp %>% 
  filter(!SiteID == "UW_Nerka Lynx Creek")

#dups removed
uw_temp %>% 
  count(StationName, sampleDate) %>% 
  filter(n > 1)

fish_tally %>% filter(Coho_count > 29) #71 site-years of fish data

#keep missing data in there so can tally missing site-years
uw_dat <- left_join(fish_tally %>% filter(Coho_count > 29), uw_temp, by = c("YearSampled" = "year", 
                                                "StationName" = "StationName")) 

#31 site-years with temp data (I was double-counting the Lynx data before)
uw_dat %>% 
  filter(!is.na(meanDT)) %>% 
  count(StationName, YearSampled) 

#saved for Erik
saveRDS(uw_dat %>% filter(!is.na(meanDT)), file = paste0("fish/data/temp_data_", Sys.Date(), ".rds"))


missing_data <- uw_dat  %>% 
  distinct(SiteID, StationName, YearSampled, Coho_count, Temp_count) %>% 
  arrange(StationName, YearSampled) %>% 
  filter(is.na(SiteID)) #identifies sites and years without temp data


```

Checked for any additional ST data that I received from Jackie, but didn't make it into the AKSSF project. 
The remaining site-years will get sent to Daniel to see if some of these can get filled in. I had historic data files for everything but Teal Creek so it may be that the only data we can fill in here are for 2021/22 and Teal Creek. We may need to develop site-specific models to interpolate these missing years. Note also looks like some sites below may have been dewatered.

Final list of missing data:

- Amou/squaw creek 2013
- Bear creek 2021, 2022
- Big Whitefish 2007-2010 and 2021 (have Aug/Sept 2007 only)
- Lynx 2008 - 2010, 2021, 2022
- Pfifer 2010, 2021
- Silver Salmon 2008, 2010, 2013
- Teal 2017
- Yako 2007-2009, 2013, 2014, 2021


Data that has been found and should be added in. For five sites, found some years that were missing, bind them together here.

```{r missing data}

bear <- read_excel("S:\\Stream Temperature Data\\Jackie Carter UW\\Jackie Carter - 2020 data request\\froRSS_AleknagikBearTemps_2008-2017.xlsx") %>%
  mutate(Date = as.Date(Date),
         Time = as_hms(Time))

ice <- read_csv("S:\\Stream Temperature Data\\Jackie Carter UW\\Jackie Carter - 2017 data request\\UW_FRI_WR_Ice_temps.csv") %>% 
  mutate(Date = as.Date(Date, format = "%m/%d/%y"))

pfifer <- read_csv("S:\\Stream Temperature Data\\Jackie Carter UW\\Jackie Carter - 2017 data request\\UW_FRI_WR_PfiferTemps.csv") %>% 
  mutate(Date = as.Date(Date, format = "%m/%d/%y"))

silver <- read_csv("S:\\Stream Temperature Data\\Jackie Carter UW\\Jackie Carter - 2017 data request\\UW_FRI_WR_SilverSalmon_Temps.csv") %>% 
  mutate(Date = as.Date(Date, format = "%m/%d/%y"))

yako <- read_csv("S:\\Stream Temperature Data\\Jackie Carter UW\\Jackie Carter - 2017 data request\\UW-FRI_YakoTemps.csv") %>% 
  mutate(Date = as.Date(Date, format = "%m/%d/%y"))

uw_temp2 <- bind_rows(bear, ice, pfifer, silver, yako)
```

Filter on the data so it only includes the years we are missing data for. This dataset will need some cleaning, looks like a fair bit of air temperatures.

```{r save data file with missing temp data}

uw_temp2 %>% 
  count(StationName, YearSampled)

uw_temp_missing <- uw_temp2 %>% 
  rowwise() %>% 
  mutate(StationName = stringr::word(StationName, 2, -1)) %>% 
  right_join(missing_data) %>% 
  group_by(StationName, Date, YearSampled) %>% 
  summarize(minDT = min(Temperature),
            maxDT = max(Temperature),
            meanDT = mean(Temperature)) %>% 
  ungroup()

uw_temp_missing %>% 
  count(StationName, YearSampled)

uw_temp_missing %>% 
  filter(!is.na(meanDT)) %>%
  ggplot() +
  geom_line(aes(x = Date, y = meanDT)) +
  geom_line(aes(x = Date, y = minDT), color = "blue") +
  geom_line(aes(x = Date, y = maxDT), color = "red") +
  facet_wrap(~StationName, scales = "free") +
  scale_x_date(date_labels = "%m/%y")

```

Final list of sites and years to send to Daniel.

```{r}

uw_found_dat_summary <- uw_temp_missing %>% 
  count(StationName, YearSampled, name = "Temp_count") %>% 
  filter(Temp_count > 1)

left_join(missing_data %>% select(-c(SiteID, Temp_count)), uw_found_dat_summary) %>% 
  filter(is.na(Temp_count)) %>% 
  # filter(YearSampled > 2020) %>% 7 are for 2021-22
  write_csv("output/fishXtemp_missing_data.csv")
```

Combined ST data files and show them on a data availability figure. There may be some sites with many years of ST to develop a model to fill any missing years that have fish, but no ST. We want to use all years of ST data for data gap filling.

NOTE - uw_temp2_daily still needs QA before using. This is for a data availability figure only.

```{r combined ST data from UW for fish sites}

uw_temp2_daily <- uw_temp2 %>% 
  rowwise() %>% 
  mutate(StationName = stringr::word(StationName, 2, -1)) %>% 
  group_by(StationName, YearSampled, Date) %>% 
  summarize(meanDT = mean(Temperature), 
            minDT = min(Temperature, na.rm = TRUE),
            maxDT = max(Temperature)) %>% 
  ungroup()

uw_temp_all <- bind_rows(uw_temp2_daily %>% 
            select(-c(minDT, maxDT)),
          uw_temp %>% 
            ungroup() %>% 
            filter(!is.na(StationName)) %>% #sites with fish data 
            # count(is.na(minDT), StationName) #lots of missing min/max, not sure why
            select(StationName, Date = sampleDate, YearSampled = year, meanDT)
          ) 

```

Data availability for both fish and ST data.

```{r}
g1 <-   ggplot() +
  geom_raster(aes(x = YearSampled, y = fct_rev(StationName), fill = log(Coho_count)),
              data = fish_tally %>% 
                filter(Coho_count > 29,
                       !grepl("Amou|Ice|Fenno|Stovall|Teal", StationName))) +
  geom_point(aes(x = YearSampled, y = fct_rev(StationName), color = "Temp. Data"),
             data = uw_temp_all %>% 
               filter(!grepl("Amou|Ice|Fenno|Stovall|Teal", StationName))) +
  scale_color_manual(values = c("Temp. Data" = "red")) +
  theme(legend.position = "bottom", axis.title.y = element_blank()) +
  labs(x = "Year", fill = "Log Coho Count", color = "")
              
g2 <- fish_tally %>% 
  filter(Coho_count > 29,
         !grepl("Amou|Ice|Fenno|Stovall|Teal", StationName)) %>% 
  ggplot(aes(x = YearSampled, y = Coho_count)) +
  geom_col() +
  facet_wrap(~StationName, scales = "free_y", ncol = 2) +
  labs(y = "Coho Count", x = "Year")

g3 <- grid.arrange(g1, g2, nrow = 1)
ggsave(plot = g3, filename = "temperature/output/data availability figure.jpeg", units = "in", width = 10, height = 6)

```

